(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{364:function(t,a,e){"use strict";e.r(a);var s=e(42),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"computer-vision-introduction-beginner"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#computer-vision-introduction-beginner"}},[t._v("#")]),t._v(" Computer Vision Introduction (Beginner)")]),t._v(" "),e("blockquote",[e("p",[t._v("A quick overview of the main features in the vision API")])]),t._v(" "),e("hr"),t._v(" "),e("p",[t._v("This article is also a Jupyter Notebook available to be run from the top down. There\nwill be code snippets that you can then run in any environment.")]),t._v(" "),e("p",[t._v("Below are the versions of "),e("code",[t._v("fastai")]),t._v(", "),e("code",[t._v("fastcore")]),t._v(", and "),e("code",[t._v("pillow")]),t._v(" currently running at the time of writing this:")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("fastai")]),t._v(": 2.0.14")]),t._v(" "),e("li",[e("code",[t._v("fastcore")]),t._v(": 1.0.11")]),t._v(" "),e("li",[e("code",[t._v("pillow")]),t._v(": 7.1.2")])]),t._v(" "),e("hr"),t._v(" "),e("h2",{attrs:{id:"general-components-of-the-vision-api"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#general-components-of-the-vision-api"}},[t._v("#")]),t._v(" General Components of the Vision API")]),t._v(" "),e("p",[t._v("In this notebook we'll be looking at the main bits and pieces that revolve around the Computer Vision sublibrary in "),e("code",[t._v("fastai")]),t._v(". We won't train a model, instead we'll show a few functions specific to vision, brielfly explain at a high level what they do, and show examples.")]),t._v(" "),e("h3",{attrs:{id:"opening-images"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#opening-images"}},[t._v("#")]),t._v(" Opening Images")]),t._v(" "),e("p",[e("code",[t._v("fastai")]),t._v(" utilizes the "),e("code",[t._v("Pillow")]),t._v(" library to open images and apply transforms. To open up any image using "),e("code",[t._v("Pillow")]),t._v(" inside the "),e("code",[t._v("fastai")]),t._v(" library, we have "),e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILImage.create",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILImage.create")]),e("OutboundLink")],1),t._v(":")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("all")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n")])])]),e("p",[t._v("We'll quickly grab the "),e("code",[t._v("PETS")]),t._v(" dataset to examine colored images:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("path "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PETS"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfnames "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_image_files"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'images'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("And open one of them with their filename:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("im "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PILImage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fnames"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("We can show the image with "),e("code",[t._v("im.show()")]),t._v(":")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("im"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("<matplotlib.axes._subplots.AxesSubplot at 0x7f8f47da2a50>\n")])])]),e("p",[e("img",{attrs:{src:"output_10_1.png",alt:"png"}})]),t._v(" "),e("p",[t._v("We can also call the usual functions you may inside of "),e("code",[t._v("Pillow")]),t._v(", such as "),e("code",[t._v(".shape")]),t._v(" and "),e("code",[t._v(".size")]),t._v(":")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("im"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" im"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size\n")])])]),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("((343, 500), (500, 343))\n")])])]),e("p",[e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILImage",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILImage")]),e("OutboundLink")],1),t._v(" can accept a varity of inputs to cover the most common types you will see in the wild:")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://docs.fast.ai/torch_core#TensorImage",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("TensorImage")]),e("OutboundLink")],1),t._v(" ("),e("code",[t._v("fastai")]),t._v(" specific)")]),t._v(" "),e("li",[e("a",{attrs:{href:"https://docs.fast.ai/torch_core#TensorMask",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("TensorMask")]),e("OutboundLink")],1),t._v(" ("),e("code",[t._v("fastai")]),t._v(" specific)")]),t._v(" "),e("li",[t._v("A "),e("code",[t._v("Tensor")])]),t._v(" "),e("li",[t._v("A "),e("code",[t._v("ndarray")])]),t._v(" "),e("li",[t._v("Bytes (note that it will call "),e("code",[t._v("io.BytesIO")]),t._v(" to open it)")]),t._v(" "),e("li",[t._v("Else it will call "),e("code",[t._v("Pillow")]),t._v("'s "),e("code",[t._v("Image.open")]),t._v(" function")])]),t._v(" "),e("p",[t._v("We can also have black and white images, which has it's own "),e("code",[t._v("PIL")]),t._v(" denomer, "),e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILImageBW",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILImageBW")]),e("OutboundLink")],1),t._v(". We'll see an example with "),e("code",[t._v("MNIST")]),t._v(" below:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("path_m "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MNIST_SAMPLE"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimgs "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_image_files"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path_m"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("im_bw "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PILImageBW"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("imgs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("And we can show just like the previous one:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("im_bw"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("<matplotlib.axes._subplots.AxesSubplot at 0x7f8f44cbb210>\n")])])]),e("p",[e("img",{attrs:{src:"output_18_1.png",alt:"png"}})]),t._v(" "),e("h3",{attrs:{id:"opening-masks"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#opening-masks"}},[t._v("#")]),t._v(" Opening Masks")]),t._v(" "),e("p",[t._v("Along with "),e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILImage",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILImage")]),e("OutboundLink")],1),t._v(" and "),e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILImageBW",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILImageBW")]),e("OutboundLink")],1),t._v(" we have "),e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILMask",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILMask")]),e("OutboundLink")],1),t._v(" designed to open masks. Let's see a quick example:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("path_c "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CAMVID_TINY"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmsks "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_image_files"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path_c"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'labels'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("msk "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PILMask"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("msks"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("msk"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("<matplotlib.axes._subplots.AxesSubplot at 0x7f8f44b0b910>\n")])])]),e("p",[e("img",{attrs:{src:"output_22_1.png",alt:"png"}})]),t._v(" "),e("p",[t._v("Each of these functions inherit from "),e("a",{attrs:{href:"https://docs.fast.ai/vision.core#PILBase",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PILBase")]),e("OutboundLink")],1),t._v(", which is a simple class that expands the usage of "),e("code",[t._v("Image.Image")]),t._v(".")]),t._v(" "),e("h2",{attrs:{id:"pairing-it-with-the-datablock"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#pairing-it-with-the-datablock"}},[t._v("#")]),t._v(" Pairing it with the "),e("a",{attrs:{href:"https://docs.fast.ai/data.block#DataBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("DataBlock")]),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("When using vision in the DataBlock API, two blocks are generally used:")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://docs.fast.ai/vision.data#ImageBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("ImageBlock")]),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://docs.fast.ai/vision.data#MaskBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("MaskBlock")]),e("OutboundLink")],1)])]),t._v(" "),e("p",[t._v("When specifying if we want a black and white image, we can pass in a "),e("code",[t._v("cls")]),t._v(" to "),e("a",{attrs:{href:"https://docs.fast.ai/vision.data#ImageBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("ImageBlock")]),e("OutboundLink")],1),t._v(" like so:")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("ImageBlock(cls=PILImageBW)")])])]),t._v(" "),e("p",[t._v("There are more tasks than simply just Semantic Segmentation, so the entire list of vision-related blocks are below:")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://docs.fast.ai/vision.data#ImageBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("ImageBlock")]),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://docs.fast.ai/vision.data#MaskBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("MaskBlock")]),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://docs.fast.ai/vision.data#BBoxBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("BBoxBlock")]),e("OutboundLink")],1),t._v(" & "),e("a",{attrs:{href:"https://docs.fast.ai/vision.data#BBoxLblBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("BBoxLblBlock")]),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://docs.fast.ai/vision.data#PointBlock",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("PointBlock")]),e("OutboundLink")],1)])]),t._v(" "),e("h2",{attrs:{id:"special-learners"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#special-learners"}},[t._v("#")]),t._v(" Special Learners")]),t._v(" "),e("p",[t._v("Each subsection of the library tends to have its own special "),e("a",{attrs:{href:"https://docs.fast.ai/learner#Learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("Learner")]),e("OutboundLink")],1),t._v(" wrappers to apply a bit of magic. For Computer Vision, this comes in the form of "),e("a",{attrs:{href:"https://docs.fast.ai/vision.learner#cnn_learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("cnn_learner")]),e("OutboundLink")],1),t._v(" and "),e("a",{attrs:{href:"https://docs.fast.ai/vision.learner#unet_learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("unet_learner")]),e("OutboundLink")],1),t._v(".")]),t._v(" "),e("p",[t._v("A quick high-level explaination of "),e("a",{attrs:{href:"https://docs.fast.ai/vision.learner#cnn_learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("cnn_learner")]),e("OutboundLink")],1),t._v(" is we can pass in a callable backbone model, "),e("code",[t._v("fastai")]),t._v(" will freeze the weights, and apply their own custom head on top with two pooling layers. You will see this referenced the most in the vision section of this website")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://docs.fast.ai/vision.learner#unet_learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("unet_learner")]),e("OutboundLink")],1),t._v(" is a method for generating a "),e("a",{attrs:{href:"https://docs.fast.ai/learner#Learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("Learner")]),e("OutboundLink")],1),t._v(" paired with the Dynamic Unet architecture and is designed specifically for segmentation (though this model "),e("em",[t._v("can")]),t._v(" be used for other tasks)")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://docs.fast.ai/vision.gan#GANLearner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("GANLearner")]),e("OutboundLink")],1),t._v(", as it would suggest, is a "),e("a",{attrs:{href:"https://docs.fast.ai/learner#Learner",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("Learner")]),e("OutboundLink")],1),t._v(" that should be used when working with "),e("code",[t._v("GANs")]),t._v(". It's a different API altogether compared to the previous two, given that GANs operate on a generator/discriminator dynamic.")]),t._v(" "),e("h2",{attrs:{id:"data-augmentation"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#data-augmentation"}},[t._v("#")]),t._v(" Data Augmentation")]),t._v(" "),e("p",[t._v("Finally, "),e("code",[t._v("fastai")]),t._v(" has a slew of data augmentation that you can apply to your dataset when training. Most commonly you will read it as something such as:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("item_tfms "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resize"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nbatch_tfms "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("aug_transforms"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("size"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),e("p",[e("a",{attrs:{href:"https://docs.fast.ai/vision.augment#aug_transforms",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("aug_transforms")]),e("OutboundLink")],1),t._v(" will generate a few random transforms that are applied efficiently on your batch.")]),t._v(" "),e("h2",{attrs:{id:"closing-remarks"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#closing-remarks"}},[t._v("#")]),t._v(" Closing Remarks")]),t._v(" "),e("p",[t._v("That is it in regards to this high-level overview. From here I would recommend reading and following any of the chapters marked with Beginner for good introductory examples, as well as helpful techniques that aren't too complex as you get familiar with the API!")])])}),[],!1,null,null,null);a.default=n.exports}}]);